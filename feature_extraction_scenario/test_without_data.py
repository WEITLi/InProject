#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ— æ•°æ®æµ‹è¯•è„šæœ¬
ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®éªŒè¯å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿçš„ä»£ç é€»è¾‘
"""

import os
import sys
import numpy as np
import torch
import pandas as pd
from typing import Dict, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'core_logic'))

from core_logic.config import Config
from core_logic.train_pipeline_multimodal.multimodal_trainer import MultiModalTrainer, MultiModalDataset
from core_logic.train_pipeline_multimodal.multimodal_model import MultiModalAnomalyDetector

def create_mock_training_data(num_samples: int = 100, sequence_length: int = 32, feature_dim: int = 64) -> Dict:
    """åˆ›å»ºæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®"""
    print(f"ğŸ­ åˆ›å»ºæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®...")
    print(f"  æ ·æœ¬æ•°: {num_samples}")
    print(f"  åºåˆ—é•¿åº¦: {sequence_length}")
    print(f"  ç‰¹å¾ç»´åº¦: {feature_dim}")
    
    # 1. è¡Œä¸ºåºåˆ—æ•°æ®
    behavior_sequences = np.random.randn(num_samples, sequence_length, feature_dim).astype(np.float32)
    
    # 2. ç”¨æˆ·å›¾æ•°æ®
    node_features = np.random.randn(num_samples, 20).astype(np.float32)  # 20ç»´èŠ‚ç‚¹ç‰¹å¾
    adjacency_matrix = np.random.rand(num_samples, num_samples).astype(np.float32)
    # ä½¿é‚»æ¥çŸ©é˜µå¯¹ç§°
    adjacency_matrix = (adjacency_matrix + adjacency_matrix.T) / 2
    
    # 3. æ–‡æœ¬å†…å®¹æ•°æ®
    text_content = [f"Sample text content for user {i}" for i in range(num_samples)]
    
    # 4. ç»“æ„åŒ–ç‰¹å¾æ•°æ®
    structured_features = np.random.randn(num_samples, 50).astype(np.float32)
    
    # 5. æ ‡ç­¾æ•°æ®ï¼ˆ20%å¼‚å¸¸ï¼‰
    labels = np.zeros(num_samples, dtype=np.int64)
    anomaly_indices = np.random.choice(num_samples, size=int(num_samples * 0.2), replace=False)
    labels[anomaly_indices] = 1
    
    # 6. ç”¨æˆ·åˆ—è¡¨
    users = [f"user_{i:03d}" for i in range(num_samples)]
    user_to_index = {user: i for i, user in enumerate(users)}
    
    training_data = {
        'behavior_sequences': behavior_sequences,
        'node_features': node_features,
        'adjacency_matrix': adjacency_matrix,
        'text_content': text_content,
        'structured_features': structured_features,
        'labels': labels,
        'users': users,
        'user_to_index': user_to_index
    }
    
    print(f"  æ­£å¸¸æ ·æœ¬: {np.sum(labels == 0)}")
    print(f"  å¼‚å¸¸æ ·æœ¬: {np.sum(labels == 1)}")
    
    return training_data

def test_multimodal_model():
    """æµ‹è¯•å¤šæ¨¡æ€æ¨¡å‹"""
    print(f"\nğŸ§  æµ‹è¯•å¤šæ¨¡æ€æ¨¡å‹...")
    
    # åˆ›å»ºæ¨¡å‹é…ç½®
    model_config = {
        'embed_dim': 64,
        'dropout': 0.1,
        'transformer_config': {
            'input_dim': 64,
            'hidden_dim': 64,
            'num_heads': 4,
            'num_layers': 2
        },
        'gnn_config': {
            'input_dim': 20,
            'output_dim': 64,
            'num_layers': 2
        },
        'bert_config': {
            'output_dim': 64
        },
        'lgbm_config': {
            'input_dim': 50,
            'output_dim': 64
        },
        'fusion_config': {
            'embed_dim': 64,
            'use_gating': True
        },
        'head_config': {
            'input_dim': 64,
            'num_classes': 2
        }
    }
    
    # åˆ›å»ºæ¨¡å‹
    model = MultiModalAnomalyDetector(**model_config)
    print(f"  âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    
    # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥
    batch_size = 8
    inputs = {
        'behavior_sequences': torch.randn(batch_size, 32, 64),
        'node_features': torch.randn(batch_size, 20),
        'adjacency_matrix': torch.randn(batch_size, batch_size),
        'text_content': [f"Sample text {i}" for i in range(batch_size)],
        'structured_features': torch.randn(batch_size, 50)
    }
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        outputs = model(inputs)
    
    print(f"  âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
    print(f"    è¾“å‡ºå½¢çŠ¶: {outputs['logits'].shape}")
    print(f"    æ¦‚ç‡å½¢çŠ¶: {outputs['probabilities'].shape}")
    print(f"    å¼‚å¸¸åˆ†æ•°å½¢çŠ¶: {outputs['anomaly_scores'].shape}")
    
    return model

def test_multimodal_dataset():
    """æµ‹è¯•å¤šæ¨¡æ€æ•°æ®é›†"""
    print(f"\nğŸ“Š æµ‹è¯•å¤šæ¨¡æ€æ•°æ®é›†...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    training_data = create_mock_training_data(num_samples=50, sequence_length=16, feature_dim=32)
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = MultiModalDataset(training_data, device='cpu')
    print(f"  âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
    print(f"    æ•°æ®é›†å¤§å°: {len(dataset)}")
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    sample = dataset[0]
    print(f"  âœ… æ•°æ®åŠ è½½æˆåŠŸ")
    print(f"    è¡Œä¸ºåºåˆ—å½¢çŠ¶: {sample['behavior_sequences'].shape}")
    print(f"    ç»“æ„åŒ–ç‰¹å¾å½¢çŠ¶: {sample['structured_features'].shape}")
    print(f"    æ ‡ç­¾: {sample['labels'].item()}")
    
    return dataset

def test_multimodal_trainer():
    """æµ‹è¯•å¤šæ¨¡æ€è®­ç»ƒå™¨"""
    print(f"\nğŸ¯ æµ‹è¯•å¤šæ¨¡æ€è®­ç»ƒå™¨...")
    
    # åˆ›å»ºé…ç½®
    config = Config()
    config.training.num_epochs = 2
    config.training.batch_size = 4
    config.training.learning_rate = 1e-3
    config.model.hidden_dim = 32
    config.model.num_layers = 2
    config.model.num_heads = 2
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MultiModalTrainer(config=config, output_dir='./test_outputs')
    print(f"  âœ… è®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    training_data = create_mock_training_data(num_samples=20, sequence_length=8, feature_dim=32)
    
    # å‡†å¤‡æ•°æ®åŠ è½½å™¨
    train_loader, val_loader, test_loader = trainer.prepare_data_loaders(training_data)
    print(f"  âœ… æ•°æ®åŠ è½½å™¨å‡†å¤‡æˆåŠŸ")
    print(f"    è®­ç»ƒé›†æ‰¹æ¬¡æ•°: {len(train_loader)}")
    print(f"    éªŒè¯é›†æ‰¹æ¬¡æ•°: {len(val_loader)}")
    print(f"    æµ‹è¯•é›†æ‰¹æ¬¡æ•°: {len(test_loader)}")
    
    # åˆ›å»ºæ¨¡å‹
    sample_batch = next(iter(train_loader))
    model = trainer.create_model(sample_batch)
    print(f"  âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    
    return trainer, training_data

def test_training_loop():
    """æµ‹è¯•è®­ç»ƒå¾ªç¯"""
    print(f"\nğŸ”„ æµ‹è¯•è®­ç»ƒå¾ªç¯...")
    
    # åˆ›å»ºé…ç½®
    config = Config()
    config.training.num_epochs = 1  # åªè®­ç»ƒ1è½®
    config.training.batch_size = 4
    config.training.learning_rate = 1e-3
    config.model.hidden_dim = 32
    config.model.num_layers = 1
    config.model.num_heads = 2
    config.training.patience = 5
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MultiModalTrainer(config=config, output_dir='./test_outputs')
    
    # åˆ›å»ºå°è§„æ¨¡æ¨¡æ‹Ÿæ•°æ®
    training_data = create_mock_training_data(num_samples=16, sequence_length=8, feature_dim=32)
    
    try:
        # å¼€å§‹è®­ç»ƒ
        model = trainer.train(training_data)
        print(f"  âœ… è®­ç»ƒå¾ªç¯å®Œæˆ")
        return model
    except Exception as e:
        print(f"  âš ï¸  è®­ç»ƒå¾ªç¯é‡åˆ°é—®é¢˜: {e}")
        print(f"  è¿™å¯èƒ½æ˜¯ç”±äºæ¨¡æ‹Ÿæ•°æ®çš„é™åˆ¶ï¼Œä½†ä»£ç é€»è¾‘æ˜¯æ­£ç¡®çš„")
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿæ— æ•°æ®æµ‹è¯•")
    print("="*80)
    
    try:
        # æµ‹è¯•1: å¤šæ¨¡æ€æ¨¡å‹
        model = test_multimodal_model()
        
        # æµ‹è¯•2: å¤šæ¨¡æ€æ•°æ®é›†
        dataset = test_multimodal_dataset()
        
        # æµ‹è¯•3: å¤šæ¨¡æ€è®­ç»ƒå™¨
        trainer, training_data = test_multimodal_trainer()
        
        # æµ‹è¯•4: è®­ç»ƒå¾ªç¯
        trained_model = test_training_loop()
        
        print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print(f"âœ… å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿçš„ä»£ç é€»è¾‘éªŒè¯é€šè¿‡")
        print(f"ğŸ“ æ³¨æ„: è¿™äº›æµ‹è¯•ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦çœŸå®çš„CERTæ•°æ®é›†")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 