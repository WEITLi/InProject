#!/usr/bin/env python3
"""æµ‹è¯•æ‰€æœ‰base_modelæ¨¡å—"""

import torch
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
# Current script: .../feature_extraction_scenario/tests/test_models.py
# Project root for imports (InProject): .../feature_extraction_scenario/../../
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, PROJECT_ROOT) # Insert at the beginning

def test_transformer():
    """æµ‹è¯•Transformerç¼–ç å™¨"""
    print("ğŸ§ª æµ‹è¯• Transformer Encoder...")
    
    from feature_extraction_scenario.core_logic.models.base_model.transformer_encoder import TransformerEncoder
    
    model = TransformerEncoder(input_dim=128, hidden_dim=256)
    x = torch.randn(16, 32, 128)
    
    with torch.no_grad():
        output = model(x)
    
    print(f"  è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print("  âœ… Transformer Encoder æµ‹è¯•é€šè¿‡")

def test_user_gnn():
    """æµ‹è¯•ç”¨æˆ·GNN"""
    print("\nğŸ§ª æµ‹è¯• User GNN...")
    
    from feature_extraction_scenario.core_logic.models.base_model.user_gnn import UserGNN
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    num_users = 50
    input_dim = 10
    
    # æ¨¡æ‹Ÿç”¨æˆ·ç‰¹å¾
    node_features = torch.randn(num_users, input_dim)
    
    # æ¨¡æ‹Ÿé‚»æ¥çŸ©é˜µï¼ˆéšæœºç¨€ç–å›¾ï¼‰
    adj_matrix = torch.rand(num_users, num_users)
    adj_matrix = (adj_matrix > 0.8).float()  # ç¨€ç–åŒ–
    adj_matrix.fill_diagonal_(1.0)  # è‡ªè¿æ¥
    
    # åº¦å½’ä¸€åŒ–
    degree = adj_matrix.sum(dim=1, keepdim=True)
    degree[degree == 0] = 1
    adj_matrix = adj_matrix / degree
    
    # åˆ›å»ºæ¨¡å‹
    model = UserGNN(
        input_dim=input_dim,
        hidden_dim=64,
        output_dim=128,
        num_layers=3
    )
    
    print(f"  èŠ‚ç‚¹ç‰¹å¾å½¢çŠ¶: {node_features.shape}")
    print(f"  é‚»æ¥çŸ©é˜µå½¢çŠ¶: {adj_matrix.shape}")
    print(f"  é‚»æ¥çŸ©é˜µå¯†åº¦: {(adj_matrix > 0).float().mean():.3f}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        user_embeddings = model(node_features, adj_matrix)
    
    print(f"  ç”¨æˆ·åµŒå…¥å½¢çŠ¶: {user_embeddings.shape}")
    print("  âœ… User GNN æµ‹è¯•é€šè¿‡")

def test_base_fusion():
    """æµ‹è¯•åŸºç¡€èåˆæ¨¡å—"""
    print("\nğŸ§ª æµ‹è¯• Base Fusion...")
    
    from feature_extraction_scenario.core_logic.models.base_model.base_fusion import BaseFusion
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 32
    features = [
        torch.randn(batch_size, 256),  # Transformerç‰¹å¾
        torch.randn(batch_size, 128),  # GNNç‰¹å¾
        torch.randn(batch_size, 512),  # BERTç‰¹å¾
        torch.randn(batch_size, 64),   # LGBMç‰¹å¾
    ]
    
    input_dims = [256, 128, 512, 64]
    output_dim = 256
    
    # æµ‹è¯•æ‹¼æ¥èåˆ
    model = BaseFusion(
        input_dims=input_dims,
        output_dim=output_dim,
        fusion_type="concat"
    )
    
    with torch.no_grad():
        output = model(features)
    
    print(f"  è¾“å…¥å½¢çŠ¶: {[f.shape for f in features]}")
    print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print("  âœ… Base Fusion æµ‹è¯•é€šè¿‡")

def test_classification_head():
    """æµ‹è¯•åˆ†ç±»å¤´"""
    print("\nğŸ§ª æµ‹è¯• Classification Head...")
    
    from feature_extraction_scenario.core_logic.models.base_model.head import ClassificationHead, AnomalyDetectionHead
    
    batch_size = 32
    input_dim = 256
    features = torch.randn(batch_size, input_dim)
    
    # æµ‹è¯•åŸºç¡€åˆ†ç±»å¤´
    classifier = ClassificationHead(
        input_dim=input_dim,
        num_classes=2,
        hidden_dims=[128, 64]
    )
    
    with torch.no_grad():
        logits = classifier(features)
        probs = classifier.predict_proba(features)
        predictions = classifier.predict(features)
    
    print(f"  åˆ†ç±»logitså½¢çŠ¶: {logits.shape}")
    print(f"  åˆ†ç±»æ¦‚ç‡å½¢çŠ¶: {probs.shape}")
    print(f"  é¢„æµ‹ç»“æœå½¢çŠ¶: {predictions.shape}")
    
    # æµ‹è¯•å¼‚å¸¸æ£€æµ‹å¤´
    anomaly_detector = AnomalyDetectionHead(
        input_dim=input_dim,
        hidden_dims=[128, 64]
    )
    
    with torch.no_grad():
        outputs = anomaly_detector(features)
    
    print(f"  å¼‚å¸¸åˆ†æ•°å½¢çŠ¶: {outputs['anomaly_score'].shape}")
    print(f"  ç½®ä¿¡åº¦å½¢çŠ¶: {outputs['confidence'].shape}")
    print("  âœ… Classification Head æµ‹è¯•é€šè¿‡")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•æ‰€æœ‰ base_model æ¨¡å—...\n")
    
    try:
        test_transformer()
        test_user_gnn()
        test_base_fusion()
        test_classification_head()
        
        print("\nğŸ‰ æ‰€æœ‰æ¨¡å—æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 