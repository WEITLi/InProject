#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Traditional Machine Learning Baseline Models
ä¼ ç»Ÿæœºå™¨å­¦ä¹ åŸºçº¿æ¨¡å‹
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score
import xgboost as xgb
import shap
from typing import Dict, Any, Tuple, List, Optional
import pickle
import os
import logging

class BaselineModelTrainer:
    """ä¼ ç»Ÿæœºå™¨å­¦ä¹ åŸºçº¿æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, model_type: str = "random_forest", random_state: int = 42):
        """
        åˆå§‹åŒ–åŸºçº¿æ¨¡å‹è®­ç»ƒå™¨
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ ("random_forest" æˆ– "xgboost")
            random_state: éšæœºç§å­
        """
        self.model_type = model_type
        self.random_state = random_state
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.feature_names = None
        
        # åˆå§‹åŒ–æ¨¡å‹
        if model_type == "random_forest":
            self.model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=random_state,
                n_jobs=-1
            )
        elif model_type == "xgboost":
            self.model = xgb.XGBClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=random_state,
                n_jobs=-1,
                eval_metric='logloss'
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
    
    def extract_traditional_features(self, multimodal_data: Dict[str, Any]) -> pd.DataFrame:
        """
        ä»å¤šæ¨¡æ€æ•°æ®ä¸­æå–ä¼ ç»Ÿæ‰‹å·¥ç‰¹å¾
        
        Args:
            multimodal_data: å¤šæ¨¡æ€æ•°æ®å­—å…¸
            
        Returns:
            ç‰¹å¾DataFrame
        """
        features_list = []
        user_ids = multimodal_data.get('users', [])
        
        # 1. è¡Œä¸ºåºåˆ—ç»Ÿè®¡ç‰¹å¾
        if 'behavior_sequences' in multimodal_data:
            behavior_data = multimodal_data['behavior_sequences']
            if isinstance(behavior_data, np.ndarray) and len(behavior_data.shape) == 3:
                # Shape: [num_users, sequence_length, feature_dim]
                for i, user_id in enumerate(user_ids):
                    if i < behavior_data.shape[0]:
                        user_sequence = behavior_data[i]  # [sequence_length, feature_dim]
                        
                        # ç»Ÿè®¡ç‰¹å¾
                        features = {
                            'user_id': user_id,
                            'seq_mean': np.mean(user_sequence),
                            'seq_std': np.std(user_sequence),
                            'seq_max': np.max(user_sequence),
                            'seq_min': np.min(user_sequence),
                            'seq_median': np.median(user_sequence),
                            'seq_skew': self._calculate_skewness(user_sequence.flatten()),
                            'seq_kurtosis': self._calculate_kurtosis(user_sequence.flatten()),
                            'seq_activity_rate': np.mean(user_sequence > 0),
                            'seq_zero_ratio': np.mean(user_sequence == 0),
                            'seq_range': np.max(user_sequence) - np.min(user_sequence)
                        }
                        
                        # æ—¶é—´åºåˆ—ç‰¹å¾
                        daily_activity = np.mean(user_sequence, axis=1)  # æ¯å¤©çš„å¹³å‡æ´»åŠ¨
                        features.update({
                            'daily_activity_mean': np.mean(daily_activity),
                            'daily_activity_std': np.std(daily_activity),
                            'daily_activity_trend': self._calculate_trend(daily_activity),
                            'peak_activity_day': np.argmax(daily_activity),
                            'activity_consistency': 1 / (1 + np.std(daily_activity))
                        })
                        
                        features_list.append(features)
        
        # 2. ç»“æ„åŒ–ç‰¹å¾
        if 'structured_features' in multimodal_data:
            structured_data = multimodal_data['structured_features']
            if isinstance(structured_data, np.ndarray):
                for i, user_id in enumerate(user_ids):
                    if i < structured_data.shape[0]:
                        user_features = structured_data[i]
                        
                        # å¦‚æœfeatures_listä¸­å·²æœ‰è¯¥ç”¨æˆ·ï¼Œåˆ™æ›´æ–°ï¼›å¦åˆ™åˆ›å»ºæ–°æ¡ç›®
                        if i < len(features_list):
                            features_list[i].update({
                                'struct_mean': np.mean(user_features),
                                'struct_std': np.std(user_features),
                                'struct_max': np.max(user_features),
                                'struct_min': np.min(user_features),
                                'struct_nonzero_count': np.count_nonzero(user_features),
                                'struct_sparsity': 1 - (np.count_nonzero(user_features) / len(user_features))
                            })
                        else:
                            features_list.append({
                                'user_id': user_id,
                                'struct_mean': np.mean(user_features),
                                'struct_std': np.std(user_features),
                                'struct_max': np.max(user_features),
                                'struct_min': np.min(user_features),
                                'struct_nonzero_count': np.count_nonzero(user_features),
                                'struct_sparsity': 1 - (np.count_nonzero(user_features) / len(user_features))
                            })
        
        # 3. å›¾ç‰¹å¾ï¼ˆå¦‚æœæœ‰èŠ‚ç‚¹ç‰¹å¾ï¼‰
        if 'node_features' in multimodal_data:
            node_features = multimodal_data['node_features']
            if isinstance(node_features, np.ndarray):
                for i, user_id in enumerate(user_ids):
                    if i < node_features.shape[0]:
                        user_node_features = node_features[i]
                        
                        graph_features = {
                            'node_feature_mean': np.mean(user_node_features),
                            'node_feature_std': np.std(user_node_features),
                            'node_centrality_proxy': np.sum(user_node_features),  # ç®€å•çš„ä¸­å¿ƒæ€§ä»£ç†
                        }
                        
                        if i < len(features_list):
                            features_list[i].update(graph_features)
                        else:
                            graph_features['user_id'] = user_id
                            features_list.append(graph_features)
        
        # 4. æ–‡æœ¬ç‰¹å¾ï¼ˆç®€å•ç»Ÿè®¡ï¼‰
        if 'text_content' in multimodal_data:
            text_data = multimodal_data['text_content']
            if isinstance(text_data, list):
                for i, user_id in enumerate(user_ids):
                    if i < len(text_data):
                        user_text = text_data[i] if text_data[i] else ""
                        
                        text_features = {
                            'text_length': len(user_text),
                            'text_word_count': len(user_text.split()) if user_text else 0,
                            'text_char_diversity': len(set(user_text.lower())) if user_text else 0,
                            'text_avg_word_length': np.mean([len(word) for word in user_text.split()]) if user_text else 0
                        }
                        
                        if i < len(features_list):
                            features_list[i].update(text_features)
                        else:
                            text_features['user_id'] = user_id
                            features_list.append(text_features)
        
        # è½¬æ¢ä¸ºDataFrame
        if features_list:
            df = pd.DataFrame(features_list)
            # å¡«å……ç¼ºå¤±å€¼
            df = df.fillna(0)
            return df
        else:
            # è¿”å›ç©ºDataFrame
            return pd.DataFrame()
    
    def _calculate_skewness(self, data: np.ndarray) -> float:
        """è®¡ç®—ååº¦"""
        if len(data) == 0 or np.std(data) == 0:
            return 0
        mean = np.mean(data)
        std = np.std(data)
        return np.mean(((data - mean) / std) ** 3)
    
    def _calculate_kurtosis(self, data: np.ndarray) -> float:
        """è®¡ç®—å³°åº¦"""
        if len(data) == 0 or np.std(data) == 0:
            return 0
        mean = np.mean(data)
        std = np.std(data)
        return np.mean(((data - mean) / std) ** 4) - 3
    
    def _calculate_trend(self, data: np.ndarray) -> float:
        """è®¡ç®—è¶‹åŠ¿ï¼ˆç®€å•çº¿æ€§å›å½’æ–œç‡ï¼‰"""
        if len(data) < 2:
            return 0
        x = np.arange(len(data))
        return np.polyfit(x, data, 1)[0]
    
    def prepare_data(self, multimodal_data: Dict[str, Any]) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®
        
        Args:
            multimodal_data: å¤šæ¨¡æ€æ•°æ®
            
        Returns:
            (X, y, feature_names)
        """
        # æå–ç‰¹å¾
        features_df = self.extract_traditional_features(multimodal_data)
        
        if features_df.empty:
            raise ValueError("æ— æ³•æå–ç‰¹å¾ï¼Œæ•°æ®å¯èƒ½ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
        
        # è·å–æ ‡ç­¾
        labels = multimodal_data.get('labels', [])
        if len(labels) == 0:
            raise ValueError("ç¼ºå°‘æ ‡ç­¾æ•°æ®")
        
        # ç¡®ä¿ç‰¹å¾å’Œæ ‡ç­¾æ•°é‡åŒ¹é…
        min_samples = min(len(features_df), len(labels))
        features_df = features_df.iloc[:min_samples]
        labels = labels[:min_samples]
        
        # ç§»é™¤user_idåˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'user_id' in features_df.columns:
            features_df = features_df.drop('user_id', axis=1)
        
        # è·å–ç‰¹å¾åç§°
        self.feature_names = list(features_df.columns)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        X = features_df.values
        y = np.array(labels)
        
        return X, y, self.feature_names
    
    def train(self, multimodal_data: Dict[str, Any], test_size: float = 0.2) -> Dict[str, Any]:
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            multimodal_data: å¤šæ¨¡æ€æ•°æ®
            test_size: æµ‹è¯•é›†æ¯”ä¾‹
            
        Returns:
            è®­ç»ƒç»“æœå­—å…¸
        """
        # å‡†å¤‡æ•°æ®
        X, y, feature_names = self.prepare_data(multimodal_data)
        
        # æ•°æ®åˆ’åˆ†
        if len(np.unique(y)) < 2 or len(y) < 4:
            # å¦‚æœæ ·æœ¬å¤ªå°‘æˆ–ç±»åˆ«ä¸è¶³ï¼Œä½¿ç”¨ç®€å•åˆ’åˆ†
            split_idx = max(1, int(len(X) * (1 - test_size)))
            X_train, X_test = X[:split_idx], X[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]
        else:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=self.random_state, stratify=y
            )
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # è®­ç»ƒæ¨¡å‹
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ {self.model_type} æ¨¡å‹...")
        self.model.fit(X_train_scaled, y_train)
        
        # é¢„æµ‹
        y_train_pred = self.model.predict(X_train_scaled)
        y_test_pred = self.model.predict(X_test_scaled)
        
        # è®¡ç®—æŒ‡æ ‡
        train_metrics = self._calculate_metrics(y_train, y_train_pred, X_train_scaled)
        test_metrics = self._calculate_metrics(y_test, y_test_pred, X_test_scaled)
        
        # ç‰¹å¾é‡è¦æ€§
        feature_importance = self._get_feature_importance()
        
        results = {
            'model_type': self.model_type,
            'train_metrics': train_metrics,
            'test_metrics': test_metrics,
            'feature_importance': feature_importance,
            'feature_names': feature_names,
            'predictions': {
                'y_train_true': y_train.tolist(),
                'y_train_pred': y_train_pred.tolist(),
                'y_test_true': y_test.tolist(),
                'y_test_pred': y_test_pred.tolist()
            }
        }
        
        print(f"âœ… {self.model_type} æ¨¡å‹è®­ç»ƒå®Œæˆ")
        print(f"   æµ‹è¯•é›† F1: {test_metrics['f1']:.4f}")
        print(f"   æµ‹è¯•é›† AUC: {test_metrics['auc']:.4f}")
        
        return results
    
    def _calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray, X: np.ndarray) -> Dict[str, float]:
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        logger = logging.getLogger(__name__) # æ·»åŠ æ—¥å¿—è®°å½•å™¨
        
        # Sanity check 1: æ£€æŸ¥ y_trueä¸­çš„ç±»åˆ«æ•°é‡
        unique_classes_true = np.unique(y_true)
        if len(unique_classes_true) < 2:
            logger.warning(f"è­¦å‘Š: y_true ä¸­åªå­˜åœ¨ä¸€ä¸ªç±»åˆ« ({unique_classes_true}). AUC å°†æ— æ³•è®¡ç®—æˆ–æ— æ„ä¹‰ã€‚è¿”å›çš„æŒ‡æ ‡å¯èƒ½ä¸å‡†ç¡®ã€‚")
            # å¯¹äºF1ç­‰æŒ‡æ ‡ï¼Œå¦‚æœåªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œå®ƒä»¬çš„è®¡ç®—ä¹Ÿå¯èƒ½ä¸ç¬¦åˆé¢„æœŸï¼Œè¿™é‡Œè¿”å›0æˆ–nanï¼Œå¹¶æç¤ºç”¨æˆ·æ£€æŸ¥æ•°æ®
            return {
                'accuracy': np.mean(y_true == y_pred), # å‡†ç¡®ç‡ä»å¯è®¡ç®—
                'f1': 0.0,
                'auc': np.nan, # AUC æ— æ³•è®¡ç®—
                'precision': 0.0,
                'recall': 0.0,
                'warning': 'y_true contains only one class'
            }

        # Sanity check 2: æ£€æŸ¥ y_pred æ˜¯å¦åªåŒ…å«ä¸€ä¸ªç±»åˆ«
        unique_classes_pred = np.unique(y_pred)
        if len(unique_classes_pred) < 2:
            logger.warning(f"è­¦å‘Š: æ¨¡å‹é¢„æµ‹ç»“æœ y_pred ä¸­åªå­˜åœ¨ä¸€ä¸ªç±»åˆ« ({unique_classes_pred}). è¿™å¯èƒ½è¡¨æ˜æ¨¡å‹å­˜åœ¨é—®é¢˜æˆ–æ•°æ®åˆ†å¸ƒæç«¯ä¸å¹³è¡¡ã€‚")

        # åŸºç¡€æŒ‡æ ‡
        f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)
        
        # AUCï¼ˆéœ€è¦æ¦‚ç‡é¢„æµ‹ï¼‰
        auc = np.nan # é»˜è®¤ä¸º nan
        y_proba_positive_class = None
        try:
            if hasattr(self.model, 'predict_proba'):
                y_proba = self.model.predict_proba(X)
                if y_proba.ndim == 2 and y_proba.shape[1] >= 2:
                    y_proba_positive_class = y_proba[:, 1] # é€šå¸¸å–æ­£ç±»çš„æ¦‚ç‡
                    
                    # Sanity check 3: æ£€æŸ¥ y_proba_positive_class æ˜¯å¦å…¨éƒ¨ç›¸åŒ
                    if len(np.unique(y_proba_positive_class)) == 1:
                        logger.warning(f"è­¦å‘Š: æ¨¡å‹é¢„æµ‹çš„æ‰€æœ‰æ ·æœ¬æ¦‚ç‡å€¼ y_score éƒ½ç›¸åŒ ({y_proba_positive_class[0]}). AUC å°†æ— æ³•è®¡ç®—æˆ–æ— æ„ä¹‰ã€‚")
                        auc = np.nan # æˆ–è€…å¯ä»¥è®¾ä¸º 0.0 æˆ– 0.5ï¼Œå–å†³äºå…·ä½“åœºæ™¯çš„å®šä¹‰
                    else:
                        auc = roc_auc_score(y_true, y_proba_positive_class)
                else:
                    logger.warning(f"è­¦å‘Š: predict_proba è¿”å›çš„æ¦‚ç‡æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ (shape: {y_proba.shape})ã€‚æ— æ³•è®¡ç®— AUCã€‚")
            else:
                logger.warning(f"è­¦å‘Š: æ¨¡å‹ {self.model_type} æ²¡æœ‰ predict_proba æ–¹æ³•ã€‚æ— æ³•è®¡ç®— AUCã€‚")
        except ValueError as e:
            # å¦‚æœ y_true ä»ç„¶å¯¼è‡´ roc_auc_score å‡ºé”™ï¼ˆä¾‹å¦‚ï¼Œåœ¨ predict_proba æ£€æŸ¥åï¼Œy_true å®é™…ä¸Šåªæœ‰ä¸€ä¸ªç±»åˆ«è¢«ä¼ å…¥ï¼‰
            logger.error(f"é”™è¯¯: è®¡ç®— AUC æ—¶å‘ç”Ÿ ValueError: {e}. è¿™å¯èƒ½ä»ç„¶æ˜¯å› ä¸º y_true ä¸­åªæœ‰ä¸€ä¸ªç±»åˆ«ã€‚")
            auc = np.nan
        except Exception as e:
            logger.error(f"é”™è¯¯: è®¡ç®— AUC æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            auc = np.nan
        
        # å‡†ç¡®ç‡
        accuracy = np.mean(y_true == y_pred)
        
        # ç²¾ç¡®ç‡å’Œå¬å›ç‡
        from sklearn.metrics import precision_score, recall_score
        precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)
        
        # å¦‚æœF1ä¸º1.0ï¼Œä½†AUCä¸ä½³ï¼Œæ·»åŠ é¢å¤–æ—¥å¿—
        if f1 == 1.0 and (np.isnan(auc) or auc < 0.6): # 0.6 æ˜¯ä¸€ä¸ªç¤ºä¾‹é˜ˆå€¼
            logger.warning(f"è­¦å‘Š: F1 åˆ†æ•°ä¸º 1.0ï¼Œä½† AUC ({auc}) è¾ƒä½æˆ–æ— æ³•è®¡ç®—ã€‚è¯·æ£€æŸ¥æ•°æ®åˆ’åˆ†ã€æ¨¡å‹è¿‡æ‹Ÿåˆæˆ–è¯„ä¼°é€»è¾‘ã€‚")
            logger.info(f"y_true unique: {np.unique(y_true, return_counts=True)}")
            logger.info(f"y_pred unique: {np.unique(y_pred, return_counts=True)}")
            if y_proba_positive_class is not None:
                 logger.info(f"y_proba_positive_class unique: {np.unique(y_proba_positive_class, return_counts=True)}")


        return {
            'accuracy': accuracy,
            'f1': f1,
            'auc': auc,
            'precision': precision,
            'recall': recall
        }
    
    def _get_feature_importance(self) -> np.ndarray:
        """è·å–ç‰¹å¾é‡è¦æ€§"""
        if hasattr(self.model, 'feature_importances_'):
            return self.model.feature_importances_
        else:
            return np.zeros(len(self.feature_names))
    
    def get_shap_values(self, X: np.ndarray, max_samples: int = 100) -> np.ndarray:
        """
        è®¡ç®—SHAPå€¼
        
        Args:
            X: è¾“å…¥ç‰¹å¾
            max_samples: æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºè®¡ç®—æ•ˆç‡ï¼‰
            
        Returns:
            SHAPå€¼æ•°ç»„
        """
        try:
            # é™åˆ¶æ ·æœ¬æ•°é‡ä»¥æé«˜è®¡ç®—æ•ˆç‡
            if len(X) > max_samples:
                indices = np.random.choice(len(X), max_samples, replace=False)
                X_sample = X[indices]
            else:
                X_sample = X
            
            # æ ‡å‡†åŒ–
            X_sample_scaled = self.scaler.transform(X_sample)
            
            # è®¡ç®—SHAPå€¼
            if self.model_type == "random_forest":
                explainer = shap.TreeExplainer(self.model)
                shap_values = explainer.shap_values(X_sample_scaled)
                if isinstance(shap_values, list):
                    shap_values = shap_values[1]  # å–æ­£ç±»çš„SHAPå€¼
            elif self.model_type == "xgboost":
                explainer = shap.TreeExplainer(self.model)
                shap_values = explainer.shap_values(X_sample_scaled)
            else:
                # ä½¿ç”¨KernelExplainerä½œä¸ºåå¤‡
                explainer = shap.KernelExplainer(self.model.predict, X_sample_scaled[:10])
                shap_values = explainer.shap_values(X_sample_scaled)
            
            return shap_values
        except Exception as e:
            print(f"âš ï¸ SHAPå€¼è®¡ç®—å¤±è´¥: {e}")
            return np.zeros((len(X), len(self.feature_names)))
    
    def save_model(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'feature_names': self.feature_names,
            'model_type': self.model_type
        }
        
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {filepath}")
    
    def load_model(self, filepath: str):
        """åŠ è½½æ¨¡å‹"""
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)
        
        self.model = model_data['model']
        self.scaler = model_data['scaler']
        self.feature_names = model_data['feature_names']
        self.model_type = model_data['model_type']
        
        print(f"ğŸ“‚ æ¨¡å‹å·²ä» {filepath} åŠ è½½")

def run_baseline_comparison(multimodal_data: Dict[str, Any], 
                          output_dir: str,
                          models: List[str] = None) -> Dict[str, Any]:
    """
    è¿è¡ŒåŸºçº¿æ¨¡å‹å¯¹æ¯”å®éªŒ
    
    Args:
        multimodal_data: å¤šæ¨¡æ€æ•°æ®
        output_dir: è¾“å‡ºç›®å½•
        models: è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨
        
    Returns:
        å¯¹æ¯”ç»“æœ
    """
    if models is None:
        models = ["random_forest", "xgboost"]
    
    results = {}
    
    for model_type in models:
        print(f"\n{'='*50}")
        print(f"ğŸ”¬ æµ‹è¯•åŸºçº¿æ¨¡å‹: {model_type}")
        print(f"{'='*50}")
        
        try:
            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = BaselineModelTrainer(model_type=model_type)
            
            # è®­ç»ƒæ¨¡å‹
            model_results = trainer.train(multimodal_data)
            
            # ä¿å­˜æ¨¡å‹
            model_path = os.path.join(output_dir, f"{model_type}_model.pkl")
            trainer.save_model(model_path)
            
            # ä¿å­˜ç»“æœ
            results[model_type] = model_results
            
        except Exception as e:
            print(f"âŒ {model_type} æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            results[model_type] = {'error': str(e)}
    
    return results 