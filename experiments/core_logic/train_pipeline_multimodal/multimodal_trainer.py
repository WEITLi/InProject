#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹è®­ç»ƒå™¨
æ•´åˆå¤šæ¨¡æ€æ•°æ®å¤„ç†å’Œæ¨¡å‹è®­ç»ƒ
"""

import os
import sys
import time
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, average_precision_score, classification_report, confusion_matrix
)
from typing import Dict, List, Tuple, Optional, Any, Union
import pickle
import json
import warnings
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
import logging # å¯¼å…¥ logging
from collections import Counter # å¯¼å…¥ Counter

warnings.filterwarnings('ignore')

# å¯¼å…¥ç›¸å…³æ¨¡å—
try:
    # å°è¯•ç›¸å¯¹å¯¼å…¥
    from ..multimodal_pipeline import MultiModalDataPipeline
    from .multimodal_model import MultiModalAnomalyDetector
    from ..config import Config, ModelConfig, TrainingConfig, DataConfig
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œæ·»åŠ è·¯å¾„å¹¶ä½¿ç”¨ç»å¯¹å¯¼å…¥
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(current_dir)
    if parent_dir not in sys.path:
        sys.path.insert(0, parent_dir)
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    
    from multimodal_pipeline import MultiModalDataPipeline
    from multimodal_model import MultiModalAnomalyDetector
    from config import Config, ModelConfig, TrainingConfig, DataConfig

class MultiModalDataset(Dataset):
    """å¤šæ¨¡æ€æ•°æ®é›†ç±»"""
    
    def __init__(self, data: Dict[str, Any], model_config: ModelConfig, data_config: DataConfig):
        """
        åˆå§‹åŒ–å¤šæ¨¡æ€æ•°æ®é›†
        
        Args:
            data: è®­ç»ƒæ•°æ®å­—å…¸
            model_config: æ¨¡å‹é…ç½®å¯¹è±¡
            data_config: æ•°æ®é…ç½®å¯¹è±¡
        """
        self.model_config = model_config
        self.data_config = data_config

        self.labels = data.get('labels', np.array([]))
        self.users = data.get('users', [])

        # Behavior sequences
        self.behavior_sequences = data.get('behavior_sequences', np.array([]))
        # Text content
        self.text_content = data.get('text_content', [])
        # Structured features
        self.structured_features = data.get('structured_features', np.array([]))
        
        # Graph-related features (some global, some per-sample)
        self.node_features = data.get('node_features', np.array([]))
        self.adjacency_matrix = data.get('adjacency_matrix', np.array([]))
        self.user_to_index = data.get('user_to_index', {})
        self.user_indices_in_graph = data.get('user_indices_in_graph', np.array([]))

        if len(self.labels) == 0:
            print("Warning: MultiModalDataset initialized with no labels.")
            # Depending on the use case, you might want to raise an error here
            # or ensure that __len__ returns 0 correctly.
            # For now, length will be 0, which might be handled by DataLoader.

    def __len__(self):
        return len(self.labels)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        item = {}
        
        # Labels (must exist if len > 0)
        if len(self.labels) > 0 :
            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)
        else:
            # This case should ideally not be reached if DataLoader uses __len__ correctly.
            # If __len__ is 0, __getitem__ shouldn't be called.
            # However, as a fallback:
            item['labels'] = torch.tensor(-1, dtype=torch.long) # Placeholder label

        # Behavior Sequences
        if hasattr(self.behavior_sequences, 'shape') and self.behavior_sequences.shape[0] > 0:
            item['behavior_sequences'] = torch.tensor(self.behavior_sequences[idx], dtype=torch.float32)
        else:
            seq_len = getattr(self.model_config, 'sequence_length', 128) # Default if not in config
            feat_dim = getattr(self.data_config, 'feature_dim', 256)    # Default if not in config
            item['behavior_sequences'] = torch.zeros((seq_len, feat_dim), dtype=torch.float32)

        # Text Content
        if self.text_content and idx < len(self.text_content): # Check if list is not empty and idx is valid
            item['text_content'] = self.text_content[idx] 
        else:
            item['text_content'] = "" # Placeholder for missing text

        # Structured Features
        if hasattr(self.structured_features, 'shape') and self.structured_features.shape[0] > 0:
            item['structured_features'] = torch.tensor(self.structured_features[idx], dtype=torch.float32)
        else:
            # Ensure structure_feat_dim is an attribute of model_config or provide a sensible default
            struct_dim = getattr(self.model_config, 'structure_feat_dim', 50) # Default if not in config
            item['structured_features'] = torch.zeros(struct_dim, dtype=torch.float32)

        # User indices in graph (per-sample data for GNN batching)
        if hasattr(self.user_indices_in_graph, 'shape') and self.user_indices_in_graph.shape[0] > 0:
            item['batch_user_indices_in_graph'] = torch.tensor(self.user_indices_in_graph[idx], dtype=torch.long)
        else:
            item['batch_user_indices_in_graph'] = torch.tensor(-1, dtype=torch.long) # Placeholder if no graph or user not in graph

        # Global graph features - node_features
        if hasattr(self.node_features, 'shape') and self.node_features.size > 0 and self.node_features.ndim > 1:
            # Ensure it's at least 2D (e.g., num_nodes, num_features)
            # self.node_features comes from data.get('node_features', np.array([]))
            # If it was np.array([]), .size is 0. If it was np.zeros((0, D)), .size is 0.
            # If it was np.zeros((1, D)), .size is D.
            item['node_features'] = torch.tensor(self.node_features, dtype=torch.float32)
        else:
            # Placeholder for node_features. 
            # The GNN input dimension will be determined by create_model based on this.
            # Use a reasonably small default, e.g., model_config.gnn_hidden_dim or a fixed small number.
            # Using a fixed number like 10 for placeholder if gnn_hidden_dim is too large or not set.
            default_node_feat_dim = getattr(self.model_config, 'gnn_input_dim_placeholder', getattr(self.model_config, 'gnn_hidden_dim', 10))
            if default_node_feat_dim <= 0: default_node_feat_dim = 10 # Ensure positive dimension
            item['node_features'] = torch.zeros((1, default_node_feat_dim), dtype=torch.float32) # Min 1 node, N features

        # Global graph features - adjacency_matrix
        if hasattr(self.adjacency_matrix, 'shape') and self.adjacency_matrix.size > 0 and self.adjacency_matrix.ndim > 1:
            item['adjacency_matrix'] = torch.tensor(self.adjacency_matrix, dtype=torch.float32)
        else:
            # Placeholder for adjacency_matrix
            item['adjacency_matrix'] = torch.zeros((1, 1), dtype=torch.float32) # Min 1x1 matrix

        # user_to_index is a dict, not typically returned per item unless specifically needed by model per batch.
        # item['user_to_index'] = self.user_to_index

        return item

class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    
    def __init__(self, patience: int = 10, min_delta: float = 0.001, 
                 restore_best_weights: bool = True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_score = None
        self.counter = 0
        self.best_weights = None
        
    def __call__(self, val_score: float, model: nn.Module) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ
        
        Args:
            val_score: éªŒè¯åˆ†æ•°
            model: æ¨¡å‹
            
        Returns:
            æ˜¯å¦åº”è¯¥æ—©åœ
        """
        if self.best_score is None:
            self.best_score = val_score
            if self.restore_best_weights:
                self.best_weights = model.state_dict().copy()
        elif val_score < self.best_score + self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                if self.restore_best_weights and self.best_weights is not None:
                    model.load_state_dict(self.best_weights)
                return True
        else:
            self.best_score = val_score
            self.counter = 0
            if self.restore_best_weights:
                self.best_weights = model.state_dict().copy()
        
        return False

class MultiModalTrainer:
    """å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹è®­ç»ƒå™¨"""
    
    def __init__(self, config: Config = None, output_dir: str = './outputs'):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            config: é…ç½®å¯¹è±¡
            output_dir: è¾“å‡ºç›®å½•
        """
        self.config = config or Config()
        self.output_dir = output_dir
        
        # ä¿®æ”¹è®¾å¤‡é€‰æ‹©é€»è¾‘
        device_setting = self.config.training.device
        if device_setting == 'auto':
            if torch.cuda.is_available():
                self.device = torch.device('cuda')
            elif torch.backends.mps.is_available(): # æ£€æŸ¥ MPS (Apple Silicon GPUs)
                self.device = torch.device('mps')
            else:
                self.device = torch.device('cpu')
        else:
            self.device = torch.device(device_setting)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # è®­ç»ƒå†å²
        self.train_history = {
            'train_loss': [], 'train_acc': [], 'train_f1': [],
            'val_loss': [], 'val_acc': [], 'val_f1': [], 'val_auc': []
        }
        
        print(f"å¤šæ¨¡æ€è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        
        # ä¿®æ”¹è®¾å¤‡æŒ‡ç¤ºçš„æ‰“å°æ–¹å¼
        device_type = self.device.type
        if device_type == 'cuda':
            print(f"  è®¾å¤‡: {self.device} (å·²å¯ç”¨ GPU åŠ é€Ÿ)")
        elif device_type == 'mps':
            print(f"  è®¾å¤‡: {self.device} (å·²å¯ç”¨ Apple Silicon GPU åŠ é€Ÿ)")
        else:
            print(f"  è®¾å¤‡: {self.device} (ä½¿ç”¨ CPU)")
            
        print(f"  è¾“å‡ºç›®å½•: {os.path.abspath(output_dir)}")
    
    def prepare_data_loaders(self, training_data: Dict[str, Any]) -> Tuple[DataLoader, DataLoader, DataLoader]:
        """
        å‡†å¤‡æ•°æ®åŠ è½½å™¨
        
        Args:
            training_data: è®­ç»ƒæ•°æ®
            
        Returns:
            è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•æ•°æ®åŠ è½½å™¨
        """
        logger = logging.getLogger(__name__) # è·å–loggerå®ä¾‹
        logger.info("å‡†å¤‡æ•°æ®åŠ è½½å™¨...")
        
        # åˆ›å»ºæ•°æ®é›† (ä¸å†ä¼ é€’ device)
        dataset = MultiModalDataset(training_data, self.config.model, self.config.data)
        
        # åˆ’åˆ†æ•°æ®é›†
        total_size = len(dataset)
        test_size = int(total_size * self.config.training.test_split)
        val_size = int(total_size * self.config.training.val_split)
        train_size = total_size - test_size - val_size
        
        train_dataset, val_dataset, test_dataset = random_split(
            dataset, [train_size, val_size, test_size],
            generator=torch.Generator().manual_seed(self.config.seed)
        )
        
        logger.info(f"æ•°æ®é›†åˆ’åˆ†: æ€»è®¡={total_size}, è®­ç»ƒé›†={train_size}, éªŒè¯é›†={val_size}, æµ‹è¯•é›†={test_size}")

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            train_dataset, 
            batch_size=self.config.training.batch_size,
            shuffle=True,
            num_workers=self.config.num_workers,
            pin_memory=True if self.device.type == 'cuda' else False
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config.training.batch_size,
            shuffle=False,
            num_workers=self.config.num_workers,
            pin_memory=True if self.device.type == 'cuda' else False
        )
        
        test_loader = DataLoader(
            test_dataset,
            batch_size=self.config.training.batch_size,
            shuffle=False,
            num_workers=self.config.num_workers,
            pin_memory=True if self.device.type == 'cuda' else False
        )
        
        print(f"æ•°æ®åŠ è½½å™¨å‡†å¤‡å®Œæˆ:")
        print(f"  è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
        print(f"  éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
        print(f"  æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
        
        return train_loader, val_loader, test_loader
    
    def create_model(self, sample_data: Dict[str, Any]) -> MultiModalAnomalyDetector:
        """
        åˆ›å»ºå¤šæ¨¡æ€æ¨¡å‹
        
        Args:
            sample_data: æ ·æœ¬æ•°æ®ç”¨äºç¡®å®šè¾“å…¥ç»´åº¦
            
        Returns:
            å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹æ¨¡å‹
        """
        print("åˆ›å»ºå¤šæ¨¡æ€æ¨¡å‹...")
        
        # è·å–è¾“å…¥ç»´åº¦ (è¿™äº›æ˜¯å®é™…æ•°æ®ç»´åº¦)
        behavior_seq_dim = sample_data['behavior_sequences'].shape[-1]
        node_feat_dim = sample_data['node_features'].shape[-1]
        struct_feat_dim = sample_data['structured_features'].shape[-1]
        
        # æ¨¡å‹ç»„ä»¶çš„å…·ä½“é…ç½®å­—å…¸
        # è¿™äº›é…ç½®å°†åŸºäº self.config.model (ModelConfig å¯¹è±¡) å’Œå®é™…è¾“å…¥ç»´åº¦æ¥æ„å»º
        
        # Transformeré…ç½®
        _transformer_config = {
            'input_dim': behavior_seq_dim, # å®é™…æ•°æ®ç»´åº¦
            'hidden_dim': self.config.model.hidden_dim,
            'num_heads': self.config.model.num_heads,
            'num_layers': self.config.model.num_layers,
            'dropout': self.config.model.dropout
        }
        
        # GNNé…ç½®  
        _gnn_config = {
            'input_dim': node_feat_dim, # å®é™…æ•°æ®ç»´åº¦
            'hidden_dim': self.config.model.gnn_hidden_dim,
            'output_dim': self.config.model.hidden_dim, # GNNè¾“å‡ºå¯¹é½
            'num_layers': self.config.model.gnn_num_layers,
            'dropout': self.config.model.gnn_dropout
        }
        
        # BERTé…ç½®
        _bert_config = {
            'bert_model_name': self.config.model.bert_model_name,
            'max_length': self.config.model.bert_max_length,
            'output_dim': self.config.model.hidden_dim, # BERTè¾“å‡ºå¯¹é½
            'dropout': self.config.model.dropout
            # BERT input_dim is implicit (vocab size handled by BERTTextEncoder)
        }
        
        # LightGBMé…ç½®
        _lgbm_config = { # LightGBMBranch å¯èƒ½éœ€è¦ä¸åŒçš„å‚æ•°å
            'input_dim': struct_feat_dim, # å®é™…æ•°æ®ç»´åº¦
            'output_dim': self.config.model.hidden_dim, # LGBMè¾“å‡ºå¯¹é½
            'num_leaves': self.config.model.lgbm_num_leaves, # ä»ModelConfigè·å–
            'max_depth': self.config.model.lgbm_max_depth,
            'learning_rate': self.config.model.lgbm_learning_rate,
            'feature_fraction': self.config.model.lgbm_feature_fraction,
            'dropout': self.config.model.dropout # Assuming LightGBMBranch might use a general dropout passed this way
        }
        
        # èåˆé…ç½®
        # input_dims for fusion will be set within MultiModalAnomalyDetector based on enabled modalities
        _fusion_config = {
            'embed_dim': self.config.model.hidden_dim,
            'dropout': self.config.model.dropout,
            # 'use_gating' from self.config.model.fusion_type or similar
        }
        
        # åˆ†ç±»å¤´é…ç½®
        _head_config = {
                'input_dim': self.config.model.hidden_dim,
            'num_classes': self.config.model.num_classes,
            'dropout': self.config.model.head_dropout
        }
        
        # åˆ›å»ºæ¨¡å‹ï¼Œä¼ å…¥ ModelConfig å¯¹è±¡å’Œå„ç»„ä»¶çš„è¯¦ç»†é…ç½®
        model = MultiModalAnomalyDetector(
            model_config_obj=self.config.model, # ä¼ é€’ ModelConfig å¯¹è±¡
            transformer_config=_transformer_config,
            gnn_config=_gnn_config,
            bert_config=_bert_config,
            lgbm_config=_lgbm_config,
            fusion_config=_fusion_config,
            head_config=_head_config
            # embed_dim and dropout are now primarily taken from model_config_obj if provided
        )
        model = model.to(self.device)
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"æ¨¡å‹åˆ›å»ºå®Œæˆ:")
        print(f"  æ€»å‚æ•°æ•°: {total_params:,}")
        print(f"  å¯è®­ç»ƒå‚æ•°æ•°: {trainable_params:,}")
        print(f"  æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")
        
        return model
    
    def train_epoch(self, model: nn.Module, train_loader: DataLoader, 
                   optimizer: optim.Optimizer, criterion: nn.Module, epoch: int) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        model.train()
        
        total_loss = 0.0
        all_predictions = []
        all_labels = []
        all_probabilities = []
        
        for batch_idx, batch_cpu in enumerate(train_loader):
            # å°†æ‰¹æ¬¡ä¸­çš„å¼ é‡ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡
            batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v for k, v in batch_cpu.items()}

            # å‡†å¤‡è¾“å…¥æ•°æ®
            inputs = {
                'behavior_sequences': batch['behavior_sequences'],
                'node_features': batch['node_features'][0],  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„èŠ‚ç‚¹ç‰¹å¾ï¼ˆæ‰€æœ‰æ ·æœ¬å…±äº«ï¼‰
                'adjacency_matrix': batch['adjacency_matrix'][0],  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„é‚»æ¥çŸ©é˜µ
                'text_content': batch['text_content'],  # ç›´æ¥ä½¿ç”¨æ‰¹å¤„ç†åçš„æ–‡æœ¬åˆ—è¡¨
                'structured_features': batch['structured_features']
            }
            
            # æ·»åŠ æ‰¹å¤„ç†ç”¨æˆ·åœ¨å›¾ä¸­çš„ç´¢å¼• (å¦‚æœå­˜åœ¨)
            if 'batch_user_indices_in_graph' in batch:
                inputs['batch_user_indices_in_graph'] = batch['batch_user_indices_in_graph']
            
            labels = batch['labels']
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            outputs = model(inputs)
            # print(f"[DEBUG MMTrain train_epoch] After model call - outputs keys: {list(outputs.keys())}")
            if 'probabilities' in outputs:
                # print(f"[DEBUG MMTrain train_epoch] After model call - outputs['probabilities'] shape: {outputs['probabilities'].shape}")
                pass # ä¿æŒç»“æ„
            else:
                # print(f"[DEBUG MMTrain train_epoch] After model call - 'probabilities' not in outputs")
                pass # ä¿æŒç»“æ„
            
            # è®¡ç®—æŸå¤±
            loss = criterion(outputs['logits'], labels)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            
            # é¢„æµ‹å’Œæ ‡ç­¾
            predictions = torch.argmax(outputs['probabilities'], dim=1)
            
            # è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥ probabilities çš„å½¢çŠ¶
            # print(f"[DEBUG MultiModalTrainer] Batch {batch_idx}: probabilities shape: {outputs['probabilities'].shape}")
            
            # å®‰å…¨åœ°è·å–å¼‚å¸¸æ¦‚ç‡
            if outputs['probabilities'].shape[1] > 1:
                probabilities = outputs['probabilities'][:, 1]  # å¼‚å¸¸æ¦‚ç‡
            else:
                # å¦‚æœåªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªï¼ˆä¹Ÿæ˜¯å”¯ä¸€çš„ï¼‰æ¦‚ç‡
                probabilities = outputs['probabilities'][:, 0]
                # print(f"[DEBUG MultiModalTrainer] Warning: probabilities only has 1 class, using [:, 0]")
            
            all_predictions.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probabilities.extend(probabilities.detach().cpu().numpy())
            
            # æ‰“å°è¿›åº¦
            if batch_idx % 10 == 0:
                print(f'  Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')
        
        # è®¡ç®—æŒ‡æ ‡
        avg_loss = total_loss / len(train_loader)
        accuracy = accuracy_score(all_labels, all_predictions)
        f1 = f1_score(all_labels, all_predictions, average='weighted')
        
        return {
            'loss': avg_loss,
            'accuracy': accuracy,
            'f1': f1,
            'predictions': all_predictions,
            'labels': all_labels,
            'probabilities': all_probabilities
        }
    
    def validate_epoch(self, model: nn.Module, val_loader: DataLoader, 
                      criterion: nn.Module) -> Dict[str, float]:
        """éªŒè¯ä¸€ä¸ªepoch"""
        model.eval()
        
        total_loss = 0.0
        all_predictions = []
        all_labels = []
        all_probabilities = []
        
        # è·å–loggerå®ä¾‹ï¼Œç”¨äºå¯èƒ½çš„æ¶ˆèå®éªŒç‰¹å®šæ—¥å¿—
        logger = logging.getLogger(__name__)
        is_ablation_single_modality_run = len(self.config.model.enabled_modalities) == 1

        with torch.no_grad():
            for batch_cpu in val_loader:
                # å°†æ‰¹æ¬¡ä¸­çš„å¼ é‡ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡
                batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v for k, v in batch_cpu.items()}

                # å‡†å¤‡è¾“å…¥æ•°æ®
                inputs = {
                    'behavior_sequences': batch['behavior_sequences'],
                    'node_features': batch['node_features'][0],
                    'adjacency_matrix': batch['adjacency_matrix'][0],
                    'text_content': batch['text_content'], # ç›´æ¥ä½¿ç”¨æ‰¹å¤„ç†åçš„æ–‡æœ¬åˆ—è¡¨
                    'structured_features': batch['structured_features']
                }
                # æ·»åŠ æ‰¹å¤„ç†ç”¨æˆ·åœ¨å›¾ä¸­çš„ç´¢å¼• (å¦‚æœå­˜åœ¨)
                if 'batch_user_indices_in_graph' in batch:
                    inputs['batch_user_indices_in_graph'] = batch['batch_user_indices_in_graph']
                
                labels = batch['labels']
                
                # å‰å‘ä¼ æ’­
                outputs = model(inputs)
                # print(f"[DEBUG MMTrain validate_epoch] After model call - outputs keys: {list(outputs.keys())}")
                if 'probabilities' in outputs:
                    # print(f"[DEBUG MMTrain validate_epoch] After model call - outputs['probabilities'] shape: {outputs['probabilities'].shape}")
                    pass # ä¿æŒç»“æ„
                else:
                    # print(f"[DEBUG MMTrain validate_epoch] After model call - 'probabilities' not in outputs")
                    pass # ä¿æŒç»“æ„
                
                loss = criterion(outputs['logits'], labels)
                
                # ç»Ÿè®¡
                total_loss += loss.item()
                
                # é¢„æµ‹å’Œæ ‡ç­¾
                predictions = torch.argmax(outputs['probabilities'], dim=1)
                
                # è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥ probabilities çš„å½¢çŠ¶
                # print(f"[DEBUG MultiModalTrainer validate] Batch {len(all_predictions)//16}: probabilities shape: {outputs['probabilities'].shape}")
                
                # å®‰å…¨åœ°è·å–å¼‚å¸¸æ¦‚ç‡
                if outputs['probabilities'].shape[1] > 1:
                    probabilities = outputs['probabilities'][:, 1]
                else:
                    # å¦‚æœåªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªï¼ˆä¹Ÿæ˜¯å”¯ä¸€çš„ï¼‰æ¦‚ç‡
                    probabilities = outputs['probabilities'][:, 0]
                    # print(f"[DEBUG MultiModalTrainer validate] Warning: probabilities only has 1 class, using [:, 0]")
                
                all_predictions.extend(predictions.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
                all_probabilities.extend(probabilities.cpu().numpy())
        
        # è®¡ç®—æŒ‡æ ‡
        avg_loss = total_loss / len(val_loader)
        accuracy = accuracy_score(all_labels, all_predictions)
        f1 = f1_score(all_labels, all_predictions, average='weighted')
        
        if is_ablation_single_modality_run:
            logger.info(f"[Ablation Val] Enabled Modalities: {self.config.model.enabled_modalities}")
            logger.info(f"[Ablation Val] Validation Labels Counter: {Counter(all_labels)}")
            logger.info(f"[Ablation Val] Validation Predictions Counter: {Counter(all_predictions)}")
            logger.info(f"[Ablation Val] Validation F1 (weighted): {f1:.5f}, Accuracy: {accuracy:.5f}")
            
            # ğŸ”§ æ·»åŠ æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            logger.info(f"[Ablation Val] Unique prediction values: {set(all_predictions)}")
            logger.info(f"[Ablation Val] Probability distribution - Mean: {np.mean(all_probabilities):.4f}, Std: {np.std(all_probabilities):.4f}")
            logger.info(f"[Ablation Val] Probability range: [{np.min(all_probabilities):.4f}, {np.max(all_probabilities):.4f}]")
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é¢„æµ‹éƒ½ç›¸åŒ
            if len(set(all_predictions)) == 1:
                logger.warning(f"[Ablation Val] âš ï¸  æ‰€æœ‰é¢„æµ‹éƒ½æ˜¯ç›¸åŒçš„å€¼: {all_predictions[0]}ï¼è¿™è¡¨æ˜æ¨¡å‹æ²¡æœ‰å­¦åˆ°æœ‰ç”¨çš„æ¨¡å¼ã€‚")
            
            # æ£€æŸ¥æ¦‚ç‡åˆ†å¸ƒæ˜¯å¦è¿‡äºé›†ä¸­
            prob_std = np.std(all_probabilities)
            if prob_std < 0.01:
                logger.warning(f"[Ablation Val] âš ï¸  æ¦‚ç‡åˆ†å¸ƒè¿‡äºé›†ä¸­ (std={prob_std:.6f})ï¼Œå¯èƒ½è¡¨æ˜æ¨¡å‹è¾“å‡ºç¼ºä¹å¤šæ ·æ€§ã€‚")

        # è®¡ç®—AUCï¼ˆå¦‚æœæœ‰æ­£è´Ÿæ ·æœ¬ï¼‰
        try:
            auc = roc_auc_score(all_labels, all_probabilities)
        except ValueError:
            auc = 0.0
        
        precision = precision_score(all_labels, all_predictions, average='weighted', zero_division=0)
        recall = recall_score(all_labels, all_predictions, average='weighted', zero_division=0)
        
        return {
            'loss': avg_loss,
            'accuracy': accuracy,
            'f1': f1,
            'auc': auc,
            'precision': precision,
            'recall': recall,
            'predictions': all_predictions,
            'labels': all_labels,
            'probabilities': all_probabilities
        }
    
    def train(self, training_data: Dict[str, Any]) -> Tuple[MultiModalAnomalyDetector, Dict[str, float]]:
        """
        å®Œæ•´çš„è®­ç»ƒæµç¨‹
        
        Args:
            training_data: è®­ç»ƒæ•°æ®
            
        Returns:
            è®­ç»ƒå¥½çš„æ¨¡å‹å’Œæœ€ç»ˆçš„æµ‹è¯•æŒ‡æ ‡
        """
        print(f"\n{'='*60}")
        print(f"å¼€å§‹å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹æ¨¡å‹è®­ç»ƒ")
        print(f"{'='*60}")
        
        start_time = time.time()
        
        # å‡†å¤‡æ•°æ®åŠ è½½å™¨
        train_loader, val_loader, test_loader = self.prepare_data_loaders(training_data)
        
        # åˆ›å»ºæ¨¡å‹
        sample_batch = next(iter(train_loader))
        model = self.create_model(sample_batch)
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.AdamW(
            model.parameters(),
            lr=self.config.training.learning_rate,
            weight_decay=self.config.training.weight_decay
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='max', factor=0.5, patience=5
        )
        
        # æ—©åœ
        early_stopping = EarlyStopping(
            patience=self.config.training.patience,
            restore_best_weights=True
        )
        
        # è®­ç»ƒå¾ªç¯
        best_val_score = -float('inf')
        
        for epoch in range(self.config.training.num_epochs):
            epoch_start_time = time.time()
            
            print(f"\nEpoch {epoch+1}/{self.config.training.num_epochs}")
            print("-" * 50)
            
            # è®­ç»ƒ
            train_metrics = self.train_epoch(model, train_loader, optimizer, criterion, epoch)
            
            # éªŒè¯
            val_metrics = self.validate_epoch(model, val_loader, criterion)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step(val_metrics['f1'])
            
            # è®°å½•å†å²
            self.train_history['train_loss'].append(train_metrics['loss'])
            self.train_history['train_acc'].append(train_metrics['accuracy'])
            self.train_history['train_f1'].append(train_metrics['f1'])
            self.train_history['val_loss'].append(val_metrics['loss'])
            self.train_history['val_acc'].append(val_metrics['accuracy'])
            self.train_history['val_f1'].append(val_metrics['f1'])
            self.train_history['val_auc'].append(val_metrics['auc'])
            
            # æ‰“å°ç»“æœ
            epoch_time = time.time() - epoch_start_time
            print(f"\nEpoch {epoch+1} å®Œæˆ ({epoch_time:.2f}s)")
            print(f"è®­ç»ƒ - Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['accuracy']:.4f}, F1: {train_metrics['f1']:.4f}")
            print(f"éªŒè¯ - Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1']:.4f}, AUC: {val_metrics['auc']:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            val_score = val_metrics['f1']  # ä½¿ç”¨F1ä½œä¸ºä¸»è¦æŒ‡æ ‡
            if val_score > best_val_score:
                best_val_score = val_score
                model_path = os.path.join(self.output_dir, 'best_model.pth')
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'config': self.config,
                    'val_score': val_score,
                    'epoch': epoch,
                    'train_history': self.train_history
                }, model_path)
                print(f"ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°: {model_path}")
            
            # æ—©åœæ£€æŸ¥
            if early_stopping(val_score, model):
                print(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
                break
        
        # æœ€ç»ˆæµ‹è¯•
        print(f"\n{'='*60}")
        print(f"åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹")
        print(f"{'='*60}")
        
        test_metrics = self.validate_epoch(model, test_loader, criterion)
        
        print(f"æµ‹è¯•ç»“æœ:")
        print(f"  å‡†ç¡®ç‡: {test_metrics['accuracy']:.4f}")
        print(f"  ç²¾ç¡®ç‡: {test_metrics['precision']:.4f}")
        print(f"  å¬å›ç‡: {test_metrics['recall']:.4f}")
        print(f"  F1åˆ†æ•°: {test_metrics['f1']:.4f}")
        print(f"  AUC: {test_metrics['auc']:.4f}")
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        test_results = {
            'test_metrics': test_metrics,
            'train_history': self.train_history,
            'config': self.config.__dict__
        }
        
        results_path = os.path.join(self.output_dir, 'test_results.json')
        
        # Helper function to convert numpy types to native Python types for JSON serialization
        def convert_numpy_types(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: convert_numpy_types(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(i) for i in obj]
            # Add other type conversions if necessary (e.g., for Config objects)
            elif hasattr(obj, '__dict__'): # For dataclasses like Config sections
                 return {k: convert_numpy_types(v) for k, v in obj.__dict__.items()}
            return obj

        serializable_results = convert_numpy_types(test_results)
        
        with open(results_path, 'w') as f:
            json.dump(serializable_results, f, indent=4)
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self.plot_training_curves()
        
        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        self.plot_confusion_matrix(test_metrics['labels'], test_metrics['predictions'])
        
        total_time = time.time() - start_time
        print(f"\n{'='*60}")
        print(f"è®­ç»ƒå®Œæˆï¼æ€»è€—æ—¶: {total_time:.2f} ç§’")
        print(f"{'-'*60}")
        
        return model, test_metrics
    
    def plot_training_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Lossæ›²çº¿
        axes[0, 0].plot(self.train_history['train_loss'], label='Train Loss')
        axes[0, 0].plot(self.train_history['val_loss'], label='Val Loss')
        axes[0, 0].set_title('Loss Curves')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True)
        
        # å‡†ç¡®ç‡æ›²çº¿
        axes[0, 1].plot(self.train_history['train_acc'], label='Train Acc')
        axes[0, 1].plot(self.train_history['val_acc'], label='Val Acc')
        axes[0, 1].set_title('Accuracy Curves')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].legend()
        axes[0, 1].grid(True)
        
        # F1åˆ†æ•°æ›²çº¿
        axes[1, 0].plot(self.train_history['train_f1'], label='Train F1')
        axes[1, 0].plot(self.train_history['val_f1'], label='Val F1')
        axes[1, 0].set_title('F1 Score Curves')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('F1 Score')
        axes[1, 0].legend()
        axes[1, 0].grid(True)
        
        # AUCæ›²çº¿
        axes[1, 1].plot(self.train_history['val_auc'], label='Val AUC')
        axes[1, 1].set_title('AUC Curve')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('AUC')
        axes[1, 1].legend()
        axes[1, 1].grid(True)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'training_curves.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"è®­ç»ƒæ›²çº¿ä¿å­˜åˆ°: {os.path.join(self.output_dir, 'training_curves.png')}")
    
    def plot_confusion_matrix(self, y_true: List[int], y_pred: List[int]):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        cm = confusion_matrix(y_true, y_pred)
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['Normal', 'Anomaly'],
                   yticklabels=['Normal', 'Anomaly'])
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        
        plt.savefig(os.path.join(self.output_dir, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"æ··æ·†çŸ©é˜µä¿å­˜åˆ°: {os.path.join(self.output_dir, 'confusion_matrix.png')}")

def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    # åˆ›å»ºé…ç½®
    config = Config()
    config.training.num_epochs = 20
    config.training.batch_size = 16
    config.training.learning_rate = 1e-4
    
    # åˆ›å»ºå¤šæ¨¡æ€æ•°æ®æµæ°´çº¿
    pipeline = MultiModalDataPipeline(
        config=config,
        data_version='r4.2',
        feature_dim=256,
        num_cores=8
    )
    
    # è¿è¡Œæ•°æ®å¤„ç†æµæ°´çº¿
    training_data = pipeline.run_full_multimodal_pipeline(
        start_week=0,
        end_week=5,
        max_users=100,
        sequence_length=128
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MultiModalTrainer(config=config, output_dir='./multimodal_outputs')
    
    # å¼€å§‹è®­ç»ƒ
    model, test_metrics = trainer.train(training_data)
    
    print("å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

if __name__ == "__main__":
    main() 