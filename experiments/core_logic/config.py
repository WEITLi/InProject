#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Multi-modal Anomaly Detection Model Configuration
å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹æ¨¡å‹é…ç½®æ–‡ä»¶
"""

import os
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Any

@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®"""
    # æ¨¡å—å¯ç”¨æ§åˆ¶
    enable_gnn: bool = True          # æ˜¯å¦å¯ç”¨GNNç”¨æˆ·å›¾åµŒå…¥
    enable_bert: bool = True         # æ˜¯å¦å¯ç”¨BERTæ–‡æœ¬ç¼–ç 
    enable_lgbm: bool = True         # æ˜¯å¦å¯ç”¨LightGBMç»“æ„åŒ–ç‰¹å¾
    enable_transformer: bool = True   # æ˜¯å¦å¯ç”¨Transformeråºåˆ—å»ºæ¨¡
    
    # æ¨¡æ€å¯ç”¨æ§åˆ¶ (ç”¨äºæ¶ˆèå®éªŒ)
    enabled_modalities: List[str] = field(default_factory=lambda: ["behavior", "graph", "text", "structured"])
    
    # æ¨¡å‹ç»´åº¦
    hidden_dim: int = 256            # éšè—å±‚ç»´åº¦
    sequence_length: int = 128       # åºåˆ—é•¿åº¦
    num_heads: int = 8               # æ³¨æ„åŠ›å¤´æ•°
    num_layers: int = 6              # Transformerå±‚æ•°
    dropout: float = 0.1             # é€šç”¨dropoutç‡
    
    # GNNé…ç½®
    gnn_hidden_dim: int = 128        # GNNéšè—ç»´åº¦
    gnn_num_layers: int = 3          # GNNå±‚æ•°
    gnn_dropout: float = 0.1         # GNN dropout
    
    # BERTé…ç½®
    bert_model_name: str = "bert-base-uncased"  # BERTæ¨¡å‹åç§°
    bert_max_length: int = 512       # BERTæœ€å¤§åºåˆ—é•¿åº¦
    bert_freeze_layers: int = 0      # å†»ç»“çš„BERTå±‚æ•°ï¼ˆ0è¡¨ç¤ºä¸å†»ç»“ï¼‰
    
    # LightGBMé…ç½®
    lgbm_num_leaves: int = 31        # LightGBMå¶å­æ•°
    lgbm_max_depth: int = -1         # LightGBMæœ€å¤§æ·±åº¦
    lgbm_learning_rate: float = 0.05  # LightGBMå­¦ä¹ ç‡
    lgbm_feature_fraction: float = 0.9  # LightGBMç‰¹å¾é‡‡æ ·ç‡
    lgbm_n_estimators: int = 100      # æ–°å¢
    lgbm_bagging_fraction: float = 0.8  # æ–°å¢
    lgbm_bagging_freq: int = 5        # æ–°å¢
    
    # èåˆé…ç½®
    fusion_type: str = "attention"   # èåˆç±»å‹ï¼šattention, concat, weighted
    fusion_hidden_dim: int = 128     # èåˆå±‚éšè—ç»´åº¦
    
    # åˆ†ç±»å¤´é…ç½®
    num_classes: int = 2             # åˆ†ç±»æ•°ï¼ˆæ­£å¸¸/å¼‚å¸¸ï¼‰
    head_dropout: float = 0.3        # åˆ†ç±»å¤´dropout

@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®"""
    # åŸºç¡€è®­ç»ƒå‚æ•°
    batch_size: int = 32             # æ‰¹å¤§å°
    learning_rate: float = 1e-4      # å­¦ä¹ ç‡
    epochs: int = 3                # è®­ç»ƒè½®æ•° (åˆ«å)
    num_epochs: int = 3           # è®­ç»ƒè½®æ•°
    warmup_steps: int = 1000         # é¢„çƒ­æ­¥æ•°
    weight_decay: float = 1e-5       # æƒé‡è¡°å‡
    device: str = "auto"             # è®­ç»ƒè®¾å¤‡
    
    # ä¼˜åŒ–å™¨é…ç½®
    optimizer: str = "adamw"         # ä¼˜åŒ–å™¨ç±»å‹
    scheduler: str = "cosine"        # å­¦ä¹ ç‡è°ƒåº¦å™¨
    
    # æ—©åœå’Œä¿å­˜
    patience: int = 10               # æ—©åœpatience
    save_top_k: int = 3             # ä¿å­˜æœ€å¥½çš„kä¸ªæ¨¡å‹
    monitor_metric: str = "val_f1"   # ç›‘æ§æŒ‡æ ‡
    
    # éªŒè¯å’Œæµ‹è¯•
    val_check_interval: int = 100    # éªŒè¯é—´éš”
    test_split: float = 0.2         # æµ‹è¯•é›†æ¯”ä¾‹
    val_split: float = 0.2          # éªŒè¯é›†æ¯”ä¾‹
    
    # æ•°æ®å¢å¼º
    enable_data_augmentation: bool = True  # æ˜¯å¦å¯ç”¨æ•°æ®å¢å¼º
    augmentation_prob: float = 0.3   # æ•°æ®å¢å¼ºæ¦‚ç‡

@dataclass
class DataConfig:
    """æ•°æ®é…ç½®"""
    data_dir: str = "../data/r4.2"  # é»˜è®¤æ•°æ®é›†è·¯å¾„ (CERT r4.2)
    processed_dir: str = "./processed_data"  # å¤„ç†åæ•°æ®çš„ä¿å­˜ç›®å½•
    max_sequence_length: int = 128  # è¡Œä¸ºåºåˆ—çš„æœ€å¤§é•¿åº¦
    min_events_per_user: int = 10  # ç”¨æˆ·æœ€å°‘äº‹ä»¶æ•°ï¼Œä½äºæ­¤å€¼çš„ç”¨æˆ·å°†è¢«è¿‡æ»¤
    max_users: Optional[int] = None  # æœ€å¤§ç”¨æˆ·æ•°ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶
    
    numerical_features: List[str] = field(default_factory=lambda: ['hour', 'day_of_week', 'event_count', 'unique_files', 'unique_urls'])
    categorical_features: List[str] = field(default_factory=lambda: ['event_type', 'department', 'role'])
    text_features: List[str] = field(default_factory=lambda: ['email_content', 'url_content', 'file_name'])
    
    time_window_days: int = 7  # æ—¶é—´çª—å£å¤§å°ï¼ˆå¤©ï¼‰
    overlap_ratio: float = 0.5  # çª—å£é‡å æ¯”ä¾‹
    
    # æ–°å¢æ•°æ®å¤„ç†ç›¸å…³å±æ€§ (for run_experiment and pipeline control)
    data_version: str = "r4.2"
    source_dir: str = "../data/r4.2" # CERT r4.2çš„æºè·¯å¾„, ç›¸å¯¹äºexperimentsç›®å½•ï¼Œå‘ä¸Š1çº§åˆ°InProject
    work_dir_base: str = "./pipeline_workdir" # æµæ°´çº¿è‡ªèº«çš„å·¥ä½œæ•°æ®ä¿å­˜åŸºç›®å½•
    start_week: int = 0
    end_week: Optional[int] = None # e.g. 5 means weeks 0,1,2,3,4
    max_weeks: int = 72  # æœ€å¤§å‘¨æ•°ï¼Œé»˜è®¤ä¸º72å‘¨
    sequence_length: int = 128 # Should be consistent with max_sequence_length
    feature_dim: int = 256 # Default feature dimension for encoder, matches MultiModalDataPipeline constructor
    num_cores: int = 8 # Default num_cores for pipeline parallel tasks
    sample_ratio: float = 1.0 # Sampling ratio for CSV reading, 1.0 means no sampling

    # å¼ºåˆ¶é‡æ–°ç”Ÿæˆæ ‡å¿—
    force_regenerate_combined_weeks: bool = False
    force_regenerate_analysis_levels: bool = False # CSV files from step4_multi_level_analysis
    force_regenerate_user_info: bool = False     
    force_regenerate_event_features: bool = False
    force_regenerate_analysis: bool = False      
    force_regenerate_training_data: bool = False 
    force_regenerate_graphs: bool = False        
    force_regenerate_sequences: bool = False     
    force_regenerate_structured_features: bool = False
    force_regenerate_text_data: bool = False # For extracted text data

@dataclass
class GeneralizationConfig:
    """æ³›åŒ–èƒ½åŠ›è¯„ä¼°å®éªŒé…ç½®"""
    num_gen_runs: int = 5  # æ³›åŒ–å®éªŒè¿è¡Œæ¬¡æ•°
    base_seed: int = 42    # æ³›åŒ–å®éªŒåŸºç¡€ç§å­

@dataclass
class Config:
    """å®Œæ•´é…ç½®"""
    model: ModelConfig = field(default_factory=ModelConfig)
    training: TrainingConfig = field(default_factory=TrainingConfig)
    data: DataConfig = field(default_factory=DataConfig)
    generalization: GeneralizationConfig = field(default_factory=GeneralizationConfig) # æ–°å¢æ³›åŒ–é…ç½®
    
    # è®¾å¤‡å’Œç¯å¢ƒ
    device: str = "cuda"             # è®¾å¤‡ç±»å‹
    num_workers: int = 4             # æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°
    seed: int = 42                   # éšæœºç§å­
    
    # æ—¥å¿—å’Œè¾“å‡º
    log_dir: str = "./logs"          # æ—¥å¿—ç›®å½•
    output_dir: str = "./outputs"    # è¾“å‡ºç›®å½•
    experiment_name: str = "multimodal_anomaly_detection"  # å®éªŒåç§°
    
    # è°ƒè¯•æ¨¡å¼
    debug: bool = False              # æ˜¯å¦ä¸ºè°ƒè¯•æ¨¡å¼
    fast_dev_run: bool = False       # å¿«é€Ÿå¼€å‘æ¨¡å¼ï¼ˆåªè¿è¡Œå°‘é‡æ•°æ®ï¼‰

def get_config() -> Config:
    """è·å–é»˜è®¤é…ç½®"""
    return Config()

def load_config_from_file(config_path: str) -> Config:
    """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
    import json
    with open(config_path, 'r') as f:
        config_dict = json.load(f)
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„é…ç½®åŠ è½½é€»è¾‘
    config = Config()
    
    # é€’å½’æ›´æ–°é…ç½®
    def update_config(config_obj, config_dict):
        for key, value in config_dict.items():
            if hasattr(config_obj, key):
                if isinstance(value, dict):
                    update_config(getattr(config_obj, key), value)
                else:
                    setattr(config_obj, key, value)
    
    update_config(config, config_dict)
    return config

def save_config_to_file(config: Config, config_path: str):
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    import json
    from dataclasses import asdict
    
    os.makedirs(os.path.dirname(config_path), exist_ok=True)
    
    with open(config_path, 'w') as f:
        json.dump(asdict(config), f, indent=2, ensure_ascii=False)

# é»˜è®¤é…ç½®å®ä¾‹
default_config = get_config()

if __name__ == "__main__":
    # æµ‹è¯•é…ç½®
    config = get_config()
    print("ğŸ”§ é…ç½®æµ‹è¯•:")
    print(f"  å¯ç”¨æ¨¡å—: GNN={config.model.enable_gnn}, BERT={config.model.enable_bert}, LGBM={config.model.enable_lgbm}")
    print(f"  æ¨¡å‹ç»´åº¦: hidden_dim={config.model.hidden_dim}")
    print(f"  è®­ç»ƒå‚æ•°: batch_size={config.training.batch_size}, lr={config.training.learning_rate}")
    print(f"  æ•°æ®è·¯å¾„: {config.data.data_dir}")
    
    # ä¿å­˜é»˜è®¤é…ç½®
    save_config_to_file(config, "configs/default_config.json")
    print("âœ… é»˜è®¤é…ç½®ä¿å­˜åˆ° configs/default_config.json") 