#!/usr/bin/env python
# coding: utf-8

"""
æµ‹è¯•è„šæœ¬ - éªŒè¯ Transformer å¨èƒæ£€æµ‹é¡¹ç›®
"""

import os
import sys
import torch
import numpy as np
import pandas as pd
from pathlib import Path

def test_imports():
    """æµ‹è¯•æ‰€æœ‰å¿…è¦çš„æ¨¡å—å¯¼å…¥"""
    print("æµ‹è¯•æ¨¡å—å¯¼å…¥...")
    
    try:
        # æµ‹è¯• PyTorch
        import torch
        print(f"âœ“ PyTorch {torch.__version__}")
        
        # æµ‹è¯•å…¶ä»–ä¾èµ–
        import numpy as np
        import pandas as pd
        import sklearn
        import matplotlib
        import seaborn
        
        print("âœ“ æ‰€æœ‰åŸºç¡€ä¾èµ–å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•è‡ªå®šä¹‰æ¨¡å—
        from data_processor import CERTDataProcessor
        from transformer_model import TransformerThreatDetector, ModelConfig
        from trainer import ThreatDetectionTrainer
        
        print("âœ“ è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        return True
        
    except ImportError as e:
        print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_config():
    """æµ‹è¯•é…ç½®ç±»"""
    print("\næµ‹è¯•é…ç½®ç±»...")
    
    try:
        from transformer_threat_detection import Config
        
        config = Config()
        print(f"âœ“ é»˜è®¤è®¾å¤‡: {config.device}")
        print(f"âœ“ åºåˆ—é•¿åº¦: {config.sequence_length}")
        print(f"âœ“ éšè—ç»´åº¦: {config.hidden_dim}")
        
        # æµ‹è¯•ä¿å­˜å’ŒåŠ è½½é…ç½®
        config.save_config('./test_config.json')
        loaded_config = Config.load_config('./test_config.json')
        
        # æ¸…ç†
        os.remove('./test_config.json')
        
        print("âœ“ é…ç½®ä¿å­˜å’ŒåŠ è½½æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âœ— é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\næµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    try:
        from transformer_model import TransformerThreatDetector, ModelConfig
        
        # åˆ›å»ºæ¨¡å‹é…ç½®
        model_config = ModelConfig(
            input_dim=50,
            context_dim=6,
            hidden_dim=64,
            num_layers=2,
            num_heads=4,
            sequence_length=10
        )
        
        # åˆ›å»ºæ¨¡å‹
        model = TransformerThreatDetector(model_config)
        
        # è®¡ç®—å‚æ•°æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {total_params:,}")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False

def test_data_processor():
    """æµ‹è¯•æ•°æ®å¤„ç†å™¨ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰"""
    print("\næµ‹è¯•æ•°æ®å¤„ç†å™¨...")
    
    try:
        from data_processor import CERTDataProcessor
        from transformer_threat_detection import Config
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        n_samples = 100
        n_features = 20
        
        data = pd.DataFrame({
            'user': [f'user_{i%10}' for i in range(n_samples)],
            'day': list(range(n_samples)),
            'insider': [0] * 95 + [1] * 5,  # 5% å¼‚å¸¸
            'role': ['employee'] * 80 + ['admin'] * 20,
            'dept': ['IT'] * 50 + ['Finance'] * 50,
            **{f'feature_{i}': np.random.randn(n_samples) for i in range(n_features)}
        })
        
        # ä¿å­˜æ¨¡æ‹Ÿæ•°æ®
        data.to_pickle('./test_data.pkl')
        
        # æµ‹è¯•æ•°æ®å¤„ç†å™¨
        config = Config()
        config.sequence_length = 5  # å‡å°åºåˆ—é•¿åº¦ç”¨äºæµ‹è¯•
        
        processor = CERTDataProcessor(config)
        processed_data = processor.process_data('./test_data.pkl')
        
        print(f"âœ“ å¤„ç†äº† {len(processed_data['sequences'])} ä¸ªåºåˆ—")
        print(f"âœ“ ç‰¹å¾ç»´åº¦: {processed_data['sequences'][0].shape}")
        print(f"âœ“ ä¸Šä¸‹æ–‡ç»´åº¦: {len(processed_data['contexts'][0])}")
        
        # æ¸…ç†
        os.remove('./test_data.pkl')
        
        return True
        
    except Exception as e:
        print(f"âœ— æ•°æ®å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        # æ¸…ç†
        if os.path.exists('./test_data.pkl'):
            os.remove('./test_data.pkl')
        return False

def test_forward_pass():
    """æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
    print("\næµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
    
    try:
        from transformer_model import TransformerThreatDetector, ModelConfig
        import torch
        
        # åˆ›å»ºæ¨¡å‹
        model_config = ModelConfig(
            input_dim=20,
            context_dim=6,
            hidden_dim=32,
            num_layers=2,
            num_heads=4,
            sequence_length=5
        )
        
        model = TransformerThreatDetector(model_config)
        model.eval()
        
        # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥
        batch_size = 4
        seq_len = 5
        
        sequences = torch.randn(batch_size, seq_len, 20)
        contexts = torch.randn(batch_size, 6)
        attention_mask = torch.ones(batch_size, seq_len)
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            outputs = model(sequences, contexts, attention_mask)
        
        print(f"âœ“ åˆ†ç±»è¾“å‡ºå½¢çŠ¶: {outputs['classification_logits'].shape}")
        print(f"âœ“ æ± åŒ–è¾“å‡ºå½¢çŠ¶: {outputs['pooled_output'].shape}")
        
        # æµ‹è¯•å¸¦æ©è”½çš„å‰å‘ä¼ æ’­
        masked_sequences = sequences.clone()
        outputs_masked = model(sequences, contexts, attention_mask, masked_sequences)
        
        print(f"âœ“ æ©è”½è¯­è¨€æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {outputs_masked['mlm_logits'].shape}")
        
        return True
        
    except Exception as e:
        print(f"âœ— å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
        return False

def check_data_files():
    """æ£€æŸ¥å¯ç”¨çš„æ•°æ®æ–‡ä»¶"""
    print("\næ£€æŸ¥å¯ç”¨çš„æ•°æ®æ–‡ä»¶...")
    
    data_files = [
        '../dayr4.2_u200_w0-3_mweekdaysession_s1-percentile14.pkl',
        '../dayr4.2_u200_w0-3_mweekdaysession_s1-meandiff14.pkl',
        '../dayr4.2_u200_w0-3_mweekdaysession_s1-meddiff14.pkl',
        '../dayr4.2_u200_w0-3_mweekdaysession_s1-concat5.pkl',
    ]
    
    available_files = []
    for file in data_files:
        if os.path.exists(file):
            size_mb = os.path.getsize(file) / (1024 * 1024)
            print(f"âœ“ {file} ({size_mb:.1f} MB)")
            available_files.append(file)
        else:
            print(f"âœ— {file} (æœªæ‰¾åˆ°)")
    
    if available_files:
        print(f"\næ¨èä½¿ç”¨: {available_files[0]}")
        return available_files[0]
    else:
        print("\nè­¦å‘Š: æœªæ‰¾åˆ°å¯ç”¨çš„æ•°æ®æ–‡ä»¶")
        return None

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("="*60)
    print("Transformer å¨èƒæ£€æµ‹é¡¹ç›®æµ‹è¯•")
    print("="*60)
    
    tests = [
        ("æ¨¡å—å¯¼å…¥", test_imports),
        ("é…ç½®ç±»", test_config),
        ("æ¨¡å‹åˆ›å»º", test_model_creation),
        ("æ•°æ®å¤„ç†å™¨", test_data_processor),
        ("å‰å‘ä¼ æ’­", test_forward_pass),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        if test_func():
            passed += 1
            print(f"âœ“ {test_name} é€šè¿‡")
        else:
            print(f"âœ— {test_name} å¤±è´¥")
    
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é¡¹ç›®å¯ä»¥æ­£å¸¸è¿è¡Œã€‚")
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        data_file = check_data_files()
        
        if data_file:
            print(f"\nğŸš€ å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼")
            print(f"ç¤ºä¾‹å‘½ä»¤:")
            print(f"python transformer_threat_detection.py \\")
            print(f"    --data_path {data_file} \\")
            print(f"    --mode train \\")
            print(f"    --few_shot_samples 100 \\")
            print(f"    --num_epochs 5 \\")
            print(f"    --output_dir ./test_outputs")
        
    else:
        print("âŒ å­˜åœ¨å¤±è´¥çš„æµ‹è¯•ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®ã€‚")
    
    print("="*60)

if __name__ == "__main__":
    main() 