Prompt：

请根据以下任务背景和研究目标，生成一个用于课程作业的上下文增强型内部威胁检测方法的完整项目代码框架，包括数据预处理、模型构建（基于 Transformer/BERT）、训练流程、小样本调试与扩展实验结构，并适配 CERT r4.2 数据集格式。

任务背景：

数据集为 CERT insider threat dataset r4.2，模拟 1000 名员工的18个月行为日志，包括登录/登出、USB 使用、文件访问、网页浏览、邮件发送、组织结构与用户上下文信息等。
恶意行为比例极低（小于 0.5%），涵盖数据泄露、知识产权盗窃、IT 破坏等多种场景，数据不平衡且模式多样。
研究目标：

构建一种上下文增强的 Transformer 模型，输入为用户每日的行为序列（日志向量序列），结合用户背景信息（如职能、部门、是否管理员等），输出是否存在威胁行为（二分类）。
支持小样本训练（可选少量恶意行为样本），并预留接口用于 Colab 上扩展全量数据实验。
支持自监督预训练（如掩蔽事件预测）与监督训练（异常检测标签），构成多任务学习。
实现包括评估指标（Precision, Recall, F1, AUC, VUS-PR）、日志级别预测输出、以及上下文信息的嵌入融合机制。
设计要求：

数据预处理模块：
日志标准化与字段提取（事件类型、时间、对象等）
用户行为序列构建（按日聚合）
(这一部份一定程度上通过了feature_extraction.py)实现
用户上下文向量构建（部门、职能、主管ID等）
日志事件 + 上下文 融合为序列输入特征张量

模型结构模块：
基于 Transformer 或 BERT 的行为序列建模
上下文特征融合策略（可选 input-level 或 output-level 融合）
多任务输出（异常分类 + 掩蔽预测）

训练与评估模块：
支持小样本调试，包含伪标签、自监督损失等选项
精度、召回率、F1、AUC、混淆矩阵评估函数
训练过程可视化与日志分析接口
扩展支持：
兼容 Colab，支持 A100 训练和大序列输入
配置文件与训练日志保存机制
可选对比模型（LSTM、随机森林等）接口
请按模块编写 Python 代码（建议 PyTorch + HuggingFace 或自定义 Transformer 实现），保留适当注释，确保便于在 Colab 中部署实验和进行小样本+全量对比分析。